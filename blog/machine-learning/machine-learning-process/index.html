<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.3.2">
<title data-rh="true">Machine Learning: Feature Scaling | Gerardo Perrucci</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://centrodph.github.io/gerardo-perrucci/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://centrodph.github.io/gerardo-perrucci/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://centrodph.github.io/gerardo-perrucci/blog/machine-learning/machine-learning-process"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Machine Learning: Feature Scaling | Gerardo Perrucci"><meta data-rh="true" name="description" content="Imagine you&#x27;re a teacher and your students are working on a group project. One student is a math whiz, another excels at writing, and a third is a history buff. If you grade each section based on the individual&#x27;s absolute strengths, the math whiz would dominate the score, even if the writing and history were excellent. This is similar to what can happen in machine learning with features (data points) on vastly different scales."><meta data-rh="true" property="og:description" content="Imagine you&#x27;re a teacher and your students are working on a group project. One student is a math whiz, another excels at writing, and a third is a history buff. If you grade each section based on the individual&#x27;s absolute strengths, the math whiz would dominate the score, even if the writing and history were excellent. This is similar to what can happen in machine learning with features (data points) on vastly different scales."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-05-27T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/centrodph"><meta data-rh="true" property="article:tag" content="Machine Learning,Data Preprocessing,Feature Scaling"><link data-rh="true" rel="icon" href="/gerardo-perrucci/img/2073951.jpeg"><link data-rh="true" rel="canonical" href="https://centrodph.github.io/gerardo-perrucci/blog/machine-learning/machine-learning-process"><link data-rh="true" rel="alternate" href="https://centrodph.github.io/gerardo-perrucci/blog/machine-learning/machine-learning-process" hreflang="en"><link data-rh="true" rel="alternate" href="https://centrodph.github.io/gerardo-perrucci/blog/machine-learning/machine-learning-process" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://centrodph.github.io/gerardo-perrucci/blog/machine-learning/machine-learning-process","mainEntityOfPage":"https://centrodph.github.io/gerardo-perrucci/blog/machine-learning/machine-learning-process","url":"https://centrodph.github.io/gerardo-perrucci/blog/machine-learning/machine-learning-process","headline":"Machine Learning: Feature Scaling","name":"Machine Learning: Feature Scaling","description":"Imagine you're a teacher and your students are working on a group project. One student is a math whiz, another excels at writing, and a third is a history buff. If you grade each section based on the individual's absolute strengths, the math whiz would dominate the score, even if the writing and history were excellent. This is similar to what can happen in machine learning with features (data points) on vastly different scales.","datePublished":"2024-05-27T00:00:00.000Z","author":{"@type":"Person","name":"Gerardo Perrucci","description":"Software Engineer","url":"https://github.com/centrodph","image":"https://avatars.githubusercontent.com/u/2073951?v=4"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://centrodph.github.io/gerardo-perrucci/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/gerardo-perrucci/blog/rss.xml" title="Gerardo Perrucci RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/gerardo-perrucci/blog/atom.xml" title="Gerardo Perrucci Atom Feed"><link rel="stylesheet" href="/gerardo-perrucci/assets/css/styles.3bd0b543.css">
<script src="/gerardo-perrucci/assets/js/runtime~main.cbc4ae01.js" defer="defer"></script>
<script src="/gerardo-perrucci/assets/js/main.81022978.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/gerardo-perrucci/"><div class="navbar__logo"><img src="/gerardo-perrucci/img/2073951.jpeg" alt="Gerardo Perrucci Website" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/gerardo-perrucci/img/2073951.jpeg" alt="Gerardo Perrucci Website" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">GP</b></a><a class="navbar__item navbar__link" href="/gerardo-perrucci/docs/about-me">About me</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/gerardo-perrucci/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/centrodph" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/gerardo-perrucci/blog/machine-learning/machine-learning-process">Machine Learning: Feature Scaling</a></li><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/gerardo-perrucci/blog/machine-learning/machine-learning-process">Machine Learning Process: A Comprehensive Guide</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/gerardo-perrucci/blog/machine-learning/machine-learning-tools">Machine Learning Environment: Python, R, RStudio, and Colab</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/gerardo-perrucci/blog/react/new-compiler-react-19">New React Compiler in React 19</a></li></ul></nav></aside><main class="col col--7"><article><header><h1 class="title_f1Hy">Machine Learning: Feature Scaling</h1><div class="container_mt6G margin-vert--md"><time datetime="2024-05-27T00:00:00.000Z">May 27, 2024</time> · <!-- -->4 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/centrodph" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://avatars.githubusercontent.com/u/2073951?v=4" alt="Gerardo Perrucci"></a><div class="avatar__intro"><div class="avatar__name"><a href="https://github.com/centrodph" target="_blank" rel="noopener noreferrer"><span>Gerardo Perrucci</span></a></div><small class="avatar__subtitle">Software Engineer</small></div></div></div></div></header><div id="__blog-post-container" class="markdown"><p>Imagine you&#x27;re a teacher and your students are working on a group project. One student is a math whiz, another excels at writing, and a third is a history buff. If you grade each section based on the individual&#x27;s absolute strengths, the math whiz would dominate the score, even if the writing and history were excellent. This is similar to what can happen in machine learning with features (data points) on vastly different scales.</p>
<p><strong>Feature scaling</strong> is a data pre-processing technique that addresses this issue. It essentially standardizes the range of features in your dataset, ensuring all features contribute equally during model training. Let&#x27;s delve deeper into why and how this works.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="why-scale">Why Scale?<a href="#why-scale" class="hash-link" aria-label="Direct link to Why Scale?" title="Direct link to Why Scale?">​</a></h3>
<ul>
<li><strong>Fair Play for All Features:</strong> Features with larger values can overshadow those with smaller ones, even if the smaller ones hold valuable information. Scaling creates a level playing field.</li>
<li><strong>Distance Matters:</strong> Many machine learning algorithms rely on calculating distances between data points. Feature scaling ensures these distances accurately reflect the underlying relationships.</li>
<li><strong>Faster &amp; More Efficient Learning:</strong> By putting features on a similar scale, the learning algorithm can converge (find an optimal solution) faster and more efficiently.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="normalization-vs-standardization-two-sides-of-the-scaling-coin">Normalization vs. Standardization: Two Sides of the Scaling Coin<a href="#normalization-vs-standardization-two-sides-of-the-scaling-coin" class="hash-link" aria-label="Direct link to Normalization vs. Standardization: Two Sides of the Scaling Coin" title="Direct link to Normalization vs. Standardization: Two Sides of the Scaling Coin">​</a></h3>
<p>Normalization and standardization are two common feature scaling techniques, and the terms are sometimes used interchangeably. However, there&#x27;s a subtle difference:</p>
<ul>
<li>
<p><strong>Normalization:</strong> This technique scales features to a specific range, typically between 0 and 1 (Min-Max Scaling) or -1 and 1. It&#x27;s useful when you know the data distribution or want to bound values within a specific range.</p>
<ul>
<li>Formula:<!-- -->
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#d6deeb;--prism-background-color:#011627"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#d6deeb;background-color:#011627"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#d6deeb"><span class="token plain">X_scaled = (X - min(X)) / (max(X) - min(X))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<!-- -->Here,
_ X_scaled is the normalized feature
_ X is the original feature value
_ min(X) is the minimum value in the feature
_ max(X) is the maximum value in the feature</li>
</ul>
</li>
<li>
<p><strong>Standardization:</strong> This technique transforms features to have a mean of 0 and a standard deviation of 1 (Z-score normalization). It assumes a Gaussian (bell-shaped) distribution for the data and emphasizes outliers more than normalization.</p>
<ul>
<li>Formula:<!-- -->
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#d6deeb;--prism-background-color:#011627"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#d6deeb;background-color:#011627"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#d6deeb"><span class="token plain">X_scaled = (X - mean(X)) / std(X)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<!-- -->Here,
_ X_scaled is the standardized feature
_ X is the original feature value
_ mean(X) is the average of all values in the feature
_ std(X) is the standard deviation of the feature</li>
</ul>
</li>
</ul>
<p><strong>Choosing the Right Technique:</strong></p>
<p>The best technique depends on your data and the specific algorithm you&#x27;re using. Here&#x27;s a general guideline:</p>
<ul>
<li>Use Min-Max scaling if the data distribution is unknown or outliers are not a concern.</li>
<li>Use standardization (Z-score) if the data is assumed to be Gaussian distributed or you want to emphasize the impact of outliers.</li>
</ul>
<p><strong>Examples:</strong></p>
<p>Imagine a dataset with two features: house price (in millions) and distance from a school (in meters). Without scaling, the massive price range would overpower the distance information. Scaling levels the field, allowing the model to learn from both features effectively.</p>
<p><strong>Further Learning:</strong></p>
<ul>
<li><a href="https://towardsdatascience.com/what-is-feature-scaling-why-is-it-important-in-machine-learning-2854ae877048" target="_blank" rel="noopener noreferrer">Feature Scaling and Why Does Machine Learning Need It</a></li>
<li><a href="https://www.geeksforgeeks.org/ml-feature-scaling-part-2/" target="_blank" rel="noopener noreferrer">Feature Engineering: Scaling, Normalization, and Standardization</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab" target="_blank" rel="noopener noreferrer">Essence of Linear Algebra</a></li>
</ul>
<p>Remember, feature scaling is a crucial step in building robust and accurate machine learning models. By ensuring all features are on the same page, you can empower your models to learn from your data more effectively.</p>
<p><strong>Choosing the Right Technique:</strong></p>
<p>The best technique depends on your data and the specific algorithm you&#x27;re using. Here&#x27;s a general guideline:</p>
<ul>
<li>Use <code>normalization</code> scaling if the data distribution is unknown or outliers are not a concern.</li>
<li>Use <code>standardization</code> (Z-score) if the data is assumed to be Gaussian distributed or you want to emphasize the impact of outliers.</li>
</ul>
<p>I hope this addition clarifies the concepts of normalization and standardization with their respective formulas!</p></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/gerardo-perrucci/blog/tags/machine-learning">Machine Learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/gerardo-perrucci/blog/tags/data-preprocessing">Data Preprocessing</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/gerardo-perrucci/blog/tags/feature-scaling">Feature Scaling</a></li></ul></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--next" href="/gerardo-perrucci/blog/machine-learning/machine-learning-process"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Machine Learning Process: A Comprehensive Guide</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#why-scale" class="table-of-contents__link toc-highlight">Why Scale?</a></li><li><a href="#normalization-vs-standardization-two-sides-of-the-scaling-coin" class="table-of-contents__link toc-highlight">Normalization vs. Standardization: Two Sides of the Scaling Coin</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Work</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://x.com/GerardoPerrucci" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://stackoverflow.com/users/6620340/gerardo-perrucci" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Life</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.instagram.com/gerardoperrucci" target="_blank" rel="noopener noreferrer" class="footer__link-item">Instagram<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://x.com/GerardoPerrucci" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>