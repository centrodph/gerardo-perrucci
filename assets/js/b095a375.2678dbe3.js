"use strict";(self.webpackChunkweb=self.webpackChunkweb||[]).push([[1219],{3230:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"machine-learning/iloc-cheatsheet","metadata":{"permalink":"/gerardo-perrucci/blog/machine-learning/iloc-cheatsheet","source":"@site/blog/machine-learning/2024-05-29-machine-learning-iloc.md","title":"Machine Learning Pandas iloc Cheatsheet","description":"The iloc indexer in pandas is a powerful tool for data selection, slicing, and manipulation, essential for preparing datasets for machine learning tasks. Here\'s a comprehensive guide to help you master iloc.","date":"2024-05-29T00:00:00.000Z","tags":[{"label":"Machine Learning","permalink":"/gerardo-perrucci/blog/tags/machine-learning"},{"label":"Data Preprocessing","permalink":"/gerardo-perrucci/blog/tags/data-preprocessing"},{"label":"iloc","permalink":"/gerardo-perrucci/blog/tags/iloc"},{"label":"pandas","permalink":"/gerardo-perrucci/blog/tags/pandas"}],"readingTime":5.635,"hasTruncateMarker":false,"authors":[{"name":"Gerardo Perrucci","title":"Software Engineer","url":"https://github.com/centrodph","imageURL":"https://avatars.githubusercontent.com/u/2073951?v=4","key":"me"}],"frontMatter":{"slug":"machine-learning/iloc-cheatsheet","title":"Machine Learning Pandas iloc Cheatsheet","authors":["me"],"tags":["Machine Learning","Data Preprocessing","iloc","pandas"],"image":"./ml-pandas-iloc.png"},"unlisted":false,"nextItem":{"title":"Machine Learning: Feature Scaling","permalink":"/gerardo-perrucci/blog/machine-learning/machine-learning-feature-scaling"}},"content":"The `iloc` indexer in pandas is a powerful tool for data selection, slicing, and manipulation, essential for preparing datasets for machine learning tasks. Here\'s a comprehensive guide to help you master `iloc`.\\n\\nYou can download the .ipynb file from [here](https://github.com/centrodph/ml/blob/main/data-processing/Pandas%20iloc%20Cheatsheet%20for%20Machine%20Learning.ipynb)\\n\\n![Machine Learning Pandas iloc Cheatsheet](./ml-pandas-iloc.png)\\n\\n## Table of Contents\\n\\n1. **Introduction to `iloc`**\\n2. **Basic Usage**\\n   - Selecting Rows\\n   - Selecting Columns\\n3. **Advanced Indexing**\\n   - Slicing Rows and Columns\\n   - Selecting Specific Rows and Columns\\n4. **Conditional Selection**\\n5. **Modifying Data**\\n6. **Practical Machine Learning Examples**\\n   - Splitting Data into Features and Target\\n   - Handling Missing Data\\n   - Data Normalization\\n7. **Oficial documentation**\\n8. **Tutorial Videos**\\n\\n## 1. Introduction to `iloc`\\n\\nThe `iloc` indexer is used for integer-location based indexing for selection by position. It is one of the primary indexers for Pandas data structures.\\n\\n```python\\nimport pandas as pd\\n\\n# Sample DataFrame\\ndata = {\\n    \'A\': [1, 2, 3, 4],\\n    \'B\': [5, 6, 7, 8],\\n    \'C\': [9, 10, 11, 12],\\n    \'D\': [13, 14, 15, 16]\\n}\\ndf = pd.DataFrame(data)\\nprint(df)\\n\\n```\\n\\n```\\n       A  B   C   D\\n    0  1  5   9  13\\n    1  2  6  10  14\\n    2  3  7  11  15\\n    3  4  8  12  16\\n```\\n\\n## 2. Basic Usage\\n\\n### Selecting Rows\\n\\nTo select rows using `iloc`, you specify the row index.\\n\\n```python\\n# Select the first row\\nprint(df.iloc[0])\\n```\\n\\n```\\n    A     1\\n    B     5\\n    C     9\\n    D    13\\n    Name: 0, dtype: int64\\n```\\n\\n```python\\n# Select the first three rows\\nprint(df.iloc[:3])\\n```\\n\\n```\\n       A  B   C   D\\n    0  1  5   9  13\\n    1  2  6  10  14\\n    2  3  7  11  15\\n```\\n\\n### Selecting Columns\\n\\nTo select columns, you specify the column index.\\n\\n```python\\n# Select the first column\\nprint(df.iloc[:, 0])\\n\\n```\\n\\n```\\n    0    1\\n    1    2\\n    2    3\\n    3    4\\n    Name: A, dtype: int64\\n```\\n\\n```python\\n# Select the first two columns\\nprint(df.iloc[:, :2])\\n```\\n\\n```\\n       A  B\\n    0  1  5\\n    1  2  6\\n    2  3  7\\n    3  4  8\\n```\\n\\n## 3. Advanced Indexing\\n\\n### Slicing Rows and Columns\\n\\nYou can slice both rows and columns simultaneously.\\n\\n```python\\n# Select the first two rows and the first two columns\\nprint(df.iloc[:2, :2])\\n```\\n\\n```\\n       A  B\\n    0  1  5\\n    1  2  6\\n```\\n\\n### Selecting Specific Rows and Columns\\n\\nSpecify exact row and column indices.\\n\\n```python\\n# Select the first and third rows and the second and fourth columns\\nprint(df.iloc[[0, 2], [1, 3]])\\n```\\n\\n```\\n       B   D\\n    0  5  13\\n    2  7  15\\n```\\n\\n## 4. Conditional Selection\\n\\nUsing `iloc` in combination with conditions.\\n\\n```python\\n# Example DataFrame\\ndf_cond = pd.DataFrame({\\n    \'A\': [1, 2, 3, 4, 5],\\n    \'B\': [10, 20, 30, 40, 50],\\n    \'C\': [100, 200, 300, 400, 500]\\n})\\n\\n# Condition to select rows where column \'A\' values are greater than 2\\nprint(df_cond[df_cond[\'A\'] > 2].iloc[:, [0, 2]])  # Select columns \'A\' and \'C\'\\n```\\n\\n```\\n       A    C\\n    2  3  300\\n    3  4  400\\n    4  5  500\\n```\\n\\n## 5. Modifying Data\\n\\nYou can use `iloc` to modify specific parts of the DataFrame.\\n\\n```python\\n# Set the value of the first cell to 0\\ndf.iloc[0, 0] = 0\\nprint(df)\\n\\n# Set the values of the first column to 0\\ndf.iloc[:, 0] = 0\\nprint(df)\\n```\\n\\n```\\n       A  B   C   D\\n    0  0  5   9  13\\n    1  2  6  10  14\\n    2  3  7  11  15\\n    3  4  8  12  16\\n       A  B   C   D\\n    0  0  5   9  13\\n    1  0  6  10  14\\n    2  0  7  11  15\\n    3  0  8  12  16\\n```\\n\\n## 6. Practical Machine Learning Examples\\n\\n### Splitting Data into Features and Target\\n\\nSeparating features (X) and target (y) is a common task.\\n\\n```python\\n# Sample DataFrame with a target column\\ndf_ml = pd.DataFrame({\\n    \'Feature1\': [1, 2, 3, 4, 5],\\n    \'Feature2\': [10, 20, 30, 40, 50],\\n    \'Target\': [0, 1, 0, 1, 0]\\n})\\n\\n# Features (all rows, all columns except the last one)\\nX = df_ml.iloc[:, :-1]\\n\\n# Target (all rows, last column)\\ny = df_ml.iloc[:, -1]\\n\\nprint(\\"Features:\\\\n\\", X)\\nprint(\\"Target:\\\\n\\", y)\\n```\\n\\n```\\n    Features:\\n        Feature1  Feature2\\n    0         1        10\\n    1         2        20\\n    2         3        30\\n    3         4        40\\n    4         5        50\\n    Target:\\n     0    0\\n    1    1\\n    2    0\\n    3    1\\n    4    0\\n    Name: Target, dtype: int64\\n```\\n\\n### Handling Missing Data\\n\\nUsing `iloc` to handle missing data by selecting specific parts of the DataFrame.\\n\\n```python\\n# Sample DataFrame with missing values\\ndf_missing = pd.DataFrame({\\n    \'A\': [1, 2, None, 4],\\n    \'B\': [5, None, 7, 8],\\n    \'C\': [None, 10, 11, 12]\\n})\\n\\n# Fill missing values in the first two columns with 0\\ndf_missing.iloc[:, :2] = df_missing.iloc[:, :2].fillna(0)\\nprint(df_missing)\\n```\\n\\n```\\n         A    B     C\\n    0  1.0  5.0   NaN\\n    1  2.0  0.0  10.0\\n    2  0.0  7.0  11.0\\n    3  4.0  8.0  12.0\\n```\\n\\n### Data Normalization\\n\\nUsing `iloc` to normalize data.\\n\\n```python\\nfrom sklearn.preprocessing import MinMaxScaler\\n\\n# Sample DataFrame for normalization\\ndf_norm = pd.DataFrame({\\n    \'Feature1\': [1, 2, 3, 4, 5],\\n    \'Feature2\': [10, 20, 30, 40, 50]\\n})\\n\\nscaler = MinMaxScaler()\\n\\n# Normalize the first two columns\\ndf_norm.iloc[:, :2] = scaler.fit_transform(df_norm.iloc[:, :2])\\nprint(df_norm)\\n```\\n\\n```\\n       Feature1  Feature2\\n    0      0.00      0.00\\n    1      0.25      0.25\\n    2      0.50      0.50\\n    3      0.75      0.75\\n    4      1.00      1.00\\n```\\n\\nCertainly! Here are some references to official documentation and YouTube videos that can help you learn more about using the `iloc` indexer in pandas for machine learning:\\n\\n## Official Documentation\\n\\n1. **Pandas Documentation on Indexing and Selecting Data:**\\n\\n   - [Pandas Official Documentation - Indexing and Selecting Data](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html)\\n   - This section of the pandas documentation provides comprehensive details on various indexing methods, including `iloc`.\\n\\n2. **Pandas API Reference for `iloc`:**\\n   - [Pandas API Reference - iloc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html)\\n   - This page contains detailed information about the `iloc` property and its usage.\\n\\n## Tutorial Videos\\n\\n1. **Corey Schafer - Python Pandas DataFrame Tutorial:**\\n\\n   - [Selecting Rows and Columns from a Pandas DataFrame](https://www.youtube.com/watch?v=ZyhVh-qRZPA&list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS&ab_channel=CoreySchafer)\\n   - This playlist covers various methods to select rows and columns in pandas DataFrames, including the use of `iloc`.\\n\\n2. **Data School - How do I select a subset of a DataFrame:**\\n\\n   - [Data School - Pandas iloc](https://www.youtube.com/watch?v=xvpNA7bC8cs)\\n   - Data School provides an in-depth tutorial on selecting subsets of DataFrames using `iloc`.\\n\\n3. **Getting Started with Data Analysis:**\\n\\n   - [Pandas DataFrames in Python](https://www.youtube.com/watch?v=ZyhVh-qRZPA)\\n   - This video explains the basics of pandas DataFrames and covers various indexing techniques including `iloc`.\\n\\n4. **Pandas Tutorial:**\\n   - [Pandas Tutorial (Data Analysis with Python)](https://www.youtube.com/watch?v=vmEHCJofslg)\\n   - A comprehensive tutorial on pandas covering many aspects including data selection and manipulation using `iloc`.\\n\\nThese resources should provide you with a strong foundation for understanding and utilizing `iloc` in pandas for your machine learning projects.\\n\\n## Conclusion\\n\\nThe `iloc` indexer is a versatile and powerful tool for data manipulation in pandas, especially useful in the preprocessing stages of machine learning. Mastering `iloc` allows for efficient and precise data selection and modification, essential for building robust machine learning models."},{"id":"machine-learning/machine-learning-feature-scaling","metadata":{"permalink":"/gerardo-perrucci/blog/machine-learning/machine-learning-feature-scaling","source":"@site/blog/machine-learning/2024-05-27-machine-learning-feature-scaling.md","title":"Machine Learning: Feature Scaling","description":"Imagine you\'re a teacher and your students are working on a group project. One student is a math whiz, another excels at writing, and a third is a history buff. If you grade each section based on the individual\'s absolute strengths, the math whiz would dominate the score, even if the writing and history were excellent. This is similar to what can happen in machine learning with features (data points) on vastly different scales.","date":"2024-05-27T00:00:00.000Z","tags":[{"label":"Machine Learning","permalink":"/gerardo-perrucci/blog/tags/machine-learning"},{"label":"Data Preprocessing","permalink":"/gerardo-perrucci/blog/tags/data-preprocessing"},{"label":"Feature Scaling","permalink":"/gerardo-perrucci/blog/tags/feature-scaling"}],"readingTime":3.15,"hasTruncateMarker":false,"authors":[{"name":"Gerardo Perrucci","title":"Software Engineer","url":"https://github.com/centrodph","imageURL":"https://avatars.githubusercontent.com/u/2073951?v=4","key":"me"}],"frontMatter":{"slug":"machine-learning/machine-learning-feature-scaling","title":"Machine Learning: Feature Scaling","authors":["me"],"tags":["Machine Learning","Data Preprocessing","Feature Scaling"],"image":"./ml-feature-scaling.webp"},"unlisted":false,"prevItem":{"title":"Machine Learning Pandas iloc Cheatsheet","permalink":"/gerardo-perrucci/blog/machine-learning/iloc-cheatsheet"},"nextItem":{"title":"Machine Learning Process: A Comprehensive Guide","permalink":"/gerardo-perrucci/blog/machine-learning/machine-learning-process"}},"content":"Imagine you\'re a teacher and your students are working on a group project. One student is a math whiz, another excels at writing, and a third is a history buff. If you grade each section based on the individual\'s absolute strengths, the math whiz would dominate the score, even if the writing and history were excellent. This is similar to what can happen in machine learning with features (data points) on vastly different scales.\\n\\n![Machine Learning Feature Scaling Source: someka.net](./ml-feature-scaling.webp)\\n\\n**Feature scaling** is a data pre-processing technique that addresses this issue. It essentially standardizes the range of features in your dataset, ensuring all features contribute equally during model training. Let\'s delve deeper into why and how this works.\\n\\n### Why Scale?\\n\\n- **Fair Play for All Features:** Features with larger values can overshadow those with smaller ones, even if the smaller ones hold valuable information. Scaling creates a level playing field.\\n- **Distance Matters:** Many machine learning algorithms rely on calculating distances between data points. Feature scaling ensures these distances accurately reflect the underlying relationships.\\n- **Faster & More Efficient Learning:** By putting features on a similar scale, the learning algorithm can converge (find an optimal solution) faster and more efficiently.\\n\\n### Normalization vs. Standardization: Two Sides of the Scaling Coin\\n\\nNormalization and standardization are two common feature scaling techniques, and the terms are sometimes used interchangeably. However, there\'s a subtle difference:\\n\\n- **Normalization:** This technique scales features to a specific range, typically between 0 and 1 (Min-Max Scaling) or -1 and 1. It\'s useful when you know the data distribution or want to bound values within a specific range.\\n\\n  - Formula:\\n\\n    ```\\n    X_scaled = (X - min(X)) / (max(X) - min(X))\\n    ```\\n\\n    Here,\\n    _ X_scaled is the normalized feature\\n    _ X is the original feature value\\n    _ min(X) is the minimum value in the feature\\n    _ max(X) is the maximum value in the feature\\n\\n- **Standardization:** This technique transforms features to have a mean of 0 and a standard deviation of 1 (Z-score normalization). It assumes a Gaussian (bell-shaped) distribution for the data and emphasizes outliers more than normalization.\\n\\n  - Formula:\\n\\n    ```\\n    X_scaled = (X - mean(X)) / std(X)\\n    ```\\n\\n    Here,\\n    _ X_scaled is the standardized feature\\n    _ X is the original feature value\\n    _ mean(X) is the average of all values in the feature\\n    _ std(X) is the standard deviation of the feature\\n\\n**Choosing the Right Technique:**\\n\\nThe best technique depends on your data and the specific algorithm you\'re using. Here\'s a general guideline:\\n\\n- Use Min-Max scaling if the data distribution is unknown or outliers are not a concern.\\n- Use standardization (Z-score) if the data is assumed to be Gaussian distributed or you want to emphasize the impact of outliers.\\n\\n**Examples:**\\n\\nImagine a dataset with two features: house price (in millions) and distance from a school (in meters). Without scaling, the massive price range would overpower the distance information. Scaling levels the field, allowing the model to learn from both features effectively.\\n\\n**Further Learning:**\\n\\n- [Feature Scaling and Why Does Machine Learning Need It](https://towardsdatascience.com/what-is-feature-scaling-why-is-it-important-in-machine-learning-2854ae877048)\\n- [Feature Engineering: Scaling, Normalization, and Standardization](https://www.geeksforgeeks.org/ml-feature-scaling-part-2/)\\n- [Essence of Linear Algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)\\n\\nRemember, feature scaling is a crucial step in building robust and accurate machine learning models. By ensuring all features are on the same page, you can empower your models to learn from your data more effectively.\\n\\n**Choosing the Right Technique:**\\n\\nThe best technique depends on your data and the specific algorithm you\'re using. Here\'s a general guideline:\\n\\n- Use `normalization` scaling if the data distribution is unknown or outliers are not a concern.\\n- Use `standardization` (Z-score) if the data is assumed to be Gaussian distributed or you want to emphasize the impact of outliers.\\n\\nI hope this addition clarifies the concepts of normalization and standardization with their respective formulas!"},{"id":"machine-learning/machine-learning-process","metadata":{"permalink":"/gerardo-perrucci/blog/machine-learning/machine-learning-process","source":"@site/blog/machine-learning/2024-05-27-machine-learning-process.md","title":"Machine Learning Process: A Comprehensive Guide","description":"Machine learning (ML) has become a cornerstone of modern technology, driving advancements in various fields such as healthcare, finance, and transportation. To build effective ML models, it\'s essential to understand the three main steps in the machine learning process: Data Preprocessing, Modeling, and Evaluation. This article breaks down these steps, detailing the sub-steps involved and providing references for further reading and understanding.","date":"2024-05-27T00:00:00.000Z","tags":[{"label":"Machine Learning","permalink":"/gerardo-perrucci/blog/tags/machine-learning"},{"label":"Data Preprocessing","permalink":"/gerardo-perrucci/blog/tags/data-preprocessing"},{"label":"Modeling","permalink":"/gerardo-perrucci/blog/tags/modeling"},{"label":"Evaluation","permalink":"/gerardo-perrucci/blog/tags/evaluation"}],"readingTime":2.1,"hasTruncateMarker":false,"authors":[{"name":"Gerardo Perrucci","title":"Software Engineer","url":"https://github.com/centrodph","imageURL":"https://avatars.githubusercontent.com/u/2073951?v=4","key":"me"}],"frontMatter":{"slug":"machine-learning/machine-learning-process","title":"Machine Learning Process: A Comprehensive Guide","authors":["me"],"tags":["Machine Learning","Data Preprocessing","Modeling","Evaluation"],"image":"./ml-process.png"},"unlisted":false,"prevItem":{"title":"Machine Learning: Feature Scaling","permalink":"/gerardo-perrucci/blog/machine-learning/machine-learning-feature-scaling"},"nextItem":{"title":"Machine Learning Environment: Python, R, RStudio, and Colab","permalink":"/gerardo-perrucci/blog/machine-learning/machine-learning-tools"}},"content":"Machine learning (ML) has become a cornerstone of modern technology, driving advancements in various fields such as healthcare, finance, and transportation. To build effective ML models, it\'s essential to understand the three main steps in the machine learning process: Data Preprocessing, Modeling, and Evaluation. This article breaks down these steps, detailing the sub-steps involved and providing references for further reading and understanding.\\n\\n![Machine Learning Process](./ml-process.png)\\n\\n## 1. Data Preprocessing\\n\\nData preprocessing is the first and arguably the most crucial step in the machine learning pipeline. This step ensures that the data is clean, consistent, and suitable for the modeling process.\\n\\n### Sub-steps:\\n\\n1. **Data Collection**: Gathering relevant data from various sources. This can include databases, APIs, and web scraping.\\n2. **Data Cleaning**: Removing or correcting any inaccuracies in the data, such as missing values, outliers, and duplicates.\\n3. **Data Transformation**: Converting data into a suitable format for analysis, which might involve normalization, standardization, or encoding categorical variables.\\n4. **Data Splitting**: Dividing the data into training, validation, and test sets to evaluate the model\'s performance.\\n\\n### References:\\n\\n- [Scikit-Learn Documentation on Data Preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html)\\n- [Kaggle Data Preprocessing Tutorial](https://www.kaggle.com/learn/data-cleaning)\\n\\n## 2. Modeling\\n\\nOnce the data is preprocessed, the next step is to build and train the machine learning model. This involves selecting the appropriate algorithm and fine-tuning it to achieve the best performance.\\n\\n### Sub-steps:\\n\\n1. **Algorithm Selection**: Choosing a machine learning algorithm based on the problem type (e.g., regression, classification, clustering).\\n2. **Model Training**: Feeding the training data into the algorithm to learn the underlying patterns and relationships.\\n3. **Hyperparameter Tuning**: Adjusting the algorithm\'s parameters to optimize performance. This can be done using techniques like grid search or random search.\\n\\n### References:\\n\\n- [Scikit-Learn Documentation on Supervised Learning](https://scikit-learn.org/stable/supervised_learning.html)\\n- [TensorFlow Model Training Guide](https://www.tensorflow.org/guide/keras/train_and_evaluate)\\n\\n## 3. Evaluation\\n\\nEvaluation is the final step in the machine learning process, where the model\'s performance is assessed to ensure it meets the desired criteria. This involves using various metrics to measure the accuracy, precision, recall, and other relevant aspects of the model.\\n\\n### Sub-steps:\\n\\n1. **Model Validation**: Using the validation set to tune the model and prevent overfitting.\\n2. **Performance Metrics**: Calculating metrics such as accuracy, precision, recall, F1 score, and AUC-ROC to evaluate the model\'s effectiveness.\\n3. **Cross-Validation**: Implementing techniques like k-fold cross-validation to ensure the model\'s robustness and reliability.\\n\\n### References:\\n\\n- [Scikit-Learn Documentation on Model Evaluation](https://scikit-learn.org/stable/modules/model_evaluation.html)\\n- [YouTube Video on Model Evaluation Metrics](https://www.youtube.com/watch?v=85dtiMz9tSo)\\n\\nUnderstanding the machine learning process is fundamental to developing effective models that can make accurate predictions and provide valuable insights."},{"id":"machine-learning/machine-learning-tools","metadata":{"permalink":"/gerardo-perrucci/blog/machine-learning/machine-learning-tools","source":"@site/blog/machine-learning/2024-05-26-machine-learning-tools.md","title":"Machine Learning Environment: Python, R, RStudio, and Colab","description":"Hi everyone! I\'m venturing into the exciting world of machine learning (ML), and this article details the tools I\'m using to get started.","date":"2024-05-26T00:00:00.000Z","tags":[{"label":"Machine Learning","permalink":"/gerardo-perrucci/blog/tags/machine-learning"},{"label":"python","permalink":"/gerardo-perrucci/blog/tags/python"},{"label":"R","permalink":"/gerardo-perrucci/blog/tags/r"},{"label":"RStudio","permalink":"/gerardo-perrucci/blog/tags/r-studio"},{"label":"Colab","permalink":"/gerardo-perrucci/blog/tags/colab"}],"readingTime":1.33,"hasTruncateMarker":false,"authors":[{"name":"Gerardo Perrucci","title":"Software Engineer","url":"https://github.com/centrodph","imageURL":"https://avatars.githubusercontent.com/u/2073951?v=4","key":"me"}],"frontMatter":{"slug":"machine-learning/machine-learning-tools","title":"Machine Learning Environment: Python, R, RStudio, and Colab","authors":["me"],"tags":["Machine Learning","python","R","RStudio","Colab"]},"unlisted":false,"prevItem":{"title":"Machine Learning Process: A Comprehensive Guide","permalink":"/gerardo-perrucci/blog/machine-learning/machine-learning-process"},"nextItem":{"title":"New React Compiler in React 19","permalink":"/gerardo-perrucci/blog/react/new-compiler-react-19"}},"content":"Hi everyone! I\'m venturing into the exciting world of machine learning (ML), and this article details the tools I\'m using to get started.\\n\\n## Essential Software\\n\\n**Python:** As a widely used general-purpose language, Python is a popular choice for ML due to its readability, extensive libraries, and large community.\\n\\nPython download: https://www.python.org/downloads/\\n\\n**R:** Another powerful language specifically designed for statistics and data analysis. R offers a rich ecosystem of packages specifically tailored for ML tasks.\\n\\nYou can download R from the official website: https://www.r-project.org/\\n\\n**RStudio:** An integrated development environment (IDE) built specifically for R. It provides a user-friendly interface for writing, running, and managing your R code. It also offers features like code completion, syntax highlighting, and debugging tools, making your R experience smoother.\\n\\nDownload RStudio from the official website: https://www.rstudio.com/products/rstudio/\\n\\n### Cloud Platform\\n\\n**Google Colab:** This fantastic platform offered by Google allows you to run Python or R code directly within your web browser. Colab provides free access to powerful hardware with GPUs (graphical processing units) that can significantly accelerate your ML computations, especially when dealing with large datasets. It\'s a great option if you don\'t have a powerful computer or prefer a cloud-based environment.\\n\\nAccess Google Colab at: Google Colab: https://colab.research.google.com/\\n\\n### Next Steps\\n\\nI\'ll delve into exploring some popular Python libraries for machine learning, such as NumPy, pandas, scikit-learn, and TensorFlow.\\n\\nBonus Tip: Jupyter Notebook is a web-based IDE that allows you to create and share documents that contain live code, equations, visualizations, and explanatory text. It\'s a great tool for documenting your ML projects and experiments.\\n\\nYou can download Jupyter Notebook: https://jupyter.org/"},{"id":"react/new-compiler-react-19","metadata":{"permalink":"/gerardo-perrucci/blog/react/new-compiler-react-19","source":"@site/blog/react/2024-05-26-new-compiler-react-19.mdx","title":"New React Compiler in React 19","description":"The new React compiler introduced in React 19 it will significantly improve React development.","date":"2024-05-26T00:00:00.000Z","tags":[{"label":"React","permalink":"/gerardo-perrucci/blog/tags/react"},{"label":"Compiler","permalink":"/gerardo-perrucci/blog/tags/compiler"},{"label":"React 19","permalink":"/gerardo-perrucci/blog/tags/react-19"}],"readingTime":1.77,"hasTruncateMarker":false,"authors":[{"name":"Gerardo Perrucci","title":"Software Engineer","url":"https://github.com/centrodph","imageURL":"https://avatars.githubusercontent.com/u/2073951?v=4","key":"me"}],"frontMatter":{"slug":"react/new-compiler-react-19","title":"New React Compiler in React 19","authors":["me"],"tags":["React","Compiler","React 19"]},"unlisted":false,"prevItem":{"title":"Machine Learning Environment: Python, R, RStudio, and Colab","permalink":"/gerardo-perrucci/blog/machine-learning/machine-learning-tools"}},"content":"**The new React compiler introduced in React 19 it will significantly improve React development.**\\n\\nReact\'s new compiler is an innovative tool designed to automatically optimize your React applications. By deeply understanding your code, the compiler applies optimizations grounded in React\u2019s core principles. These optimizations can lead to significant performance enhancements, especially for complex applications.\\n\\nCurrently in its experimental phase, the new compiler has the potential to revolutionize React development. It\'s particularly interesting to see how it will interact with the `inline` optimization technique used in React like memo, useMemo useCallback.\\n\\nThe ongoing development and integration of the compiler promise exciting advancements in the efficiency and performance of React applications. As the tool matures, it could become a game-changer for developers seeking to build faster, more efficient applications.\\n\\nSome bullet points to consider:\\n\\n    - A new experimental tool called the React compiler can automatically optimize your React application.\\n\\n    - It accomplishes this by thoroughly comprehending the code and applying optimizations based on React\'s principles.\\n\\n    - This can result in performance improvements, particularly for intricate applications.\\n\\n    - The compiler is still in its experimental phase, but it has the potential to revolutionize React development.\\n\\n    - It will be interesting to see how it affects the `inline` optimization technique used in React like memo, useMemo useCallback.\\n\\nSure, according to the document (https://react.dev/learn/react-compiler), the React compiler can optimize your React application in a few specific cases.\\n\\n**It can automatically memoize certain values or groups of values within your components and hooks.** This means it can cache the results of functions so that they don\'t have to be recalculated every time the component renders if the inputs haven\'t changed.\\n\\nIn addition, the compiler can skip over re-rendering components that haven\'t changed. For instance, if a parent component re-renders, it won\'t necessarily force all of its child components to re-render as well. Finally, is important to note that the code is expected to follow the **React Rules** in order to work properly with the compiler. Learn more about the React Rules: https://react.dev/reference/rules\\n\\n<iframe\\n  width=\\"560\\"\\n  height=\\"315\\"\\n  src=\\"https://www.youtube.com/embed/Xo-ddmNGjY8?si=EfLo6F1IM1O7PUll\\"\\n  title=\\"YouTube video player\\"\\n  frameborder=\\"0\\"\\n  allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\"\\n  referrerpolicy=\\"strict-origin-when-cross-origin\\"\\n  allowfullscreen\\n></iframe>"}]}}')}}]);